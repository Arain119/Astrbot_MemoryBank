import json
import os
import datetime
import logging
from typing import List, Dict
import asyncio

from astrbot.api.event import AstrMessageEvent
from astrbot.api.event.filter import event_message_type, EventMessageType
from astrbot.api.star import Context, Star, register
from astrbot.api.event.filter import command, command_group, llm_tool, on_decorating_result
from sentence_transformers import SentenceTransformer, util
import httpx

logger = logging.getLogger("astrbot")


@register("ai_memory_longterm", "kjqwdw", "ä¸€ä¸ªé•¿ä¹…è®°å¿†æ’ä»¶", "1.0.0")
class Main(Star):
    def __init__(self, context: Context, config: dict):
        super().__init__(context)
        self.PLUGIN_NAME = "ai_memory_longterm"

        plugin_dir = os.path.dirname(os.path.abspath(__file__))
        self.summary_file = os.path.join(plugin_dir, "summary_data.json")
        self.memory_file = os.path.join(plugin_dir, "memory_data.json")

        if not os.path.exists(self.summary_file):
            with open(self.summary_file, "w", encoding='utf-8') as f:
                f.write("{}")

        if not os.path.exists(self.memory_file):
            with open(self.memory_file, "w", encoding='utf-8') as f:
                f.write("{}")

        with open(self.summary_file, "r", encoding='utf-8') as f:
            self.summaries = json.load(f)

        try:
            with open(self.memory_file, "r", encoding='utf-8') as f:
                self.memory_data = json.load(f)
        except (FileNotFoundError, json.JSONDecodeError):
            self.memory_data = {}
            with open(self.memory_file, "w", encoding='utf-8') as f:
                json.dump(self.memory_data, f, ensure_ascii=False)

        self.max_summaries = config.get("max_summaries", 5)
        self.similarity_threshold = config.get("similarity_threshold", 0.7)
        self.summary_model = config.get("summary_model", "paraphrase-multilingual-MiniLM-L12-v2")
        self.embedding_model = SentenceTransformer(self.summary_model, local_files_only=True)
        self.siliconflow_api_key = config.get("siliconflow_api_key", "")
        self.siliconflow_model = config.get("siliconflow_model", "Qwen/Qwen2.5-7B-Instruct")
        self.auto_summary_interval = config.get("auto_summary_interval", 10)  # è¯»å–æ–°çš„é…ç½®é¡¹

        self.locks = {}  # ç”¨äºå­˜å‚¨æ¯ä¸ªä¼šè¯çš„é”

    @command_group("memory")
    def memory(self):
        """è®°å¿†ç®¡ç†æŒ‡ä»¤ç»„"""
        pass

    @memory.command("list")
    async def list_summaries(self, event: AstrMessageEvent):
        """åˆ—å‡ºæ‰€æœ‰æ‘˜è¦"""
        session_id = self._get_unified_session_id(event)
        if session_id not in self.summaries or not self.summaries[session_id]:
            return event.plain_result("å½“å‰ä¼šè¯æ²¡æœ‰æ‘˜è¦ã€‚")

        summaries_text = "å·²ä¿å­˜çš„æ‘˜è¦:\n"
        for i, summary in enumerate(self.summaries[session_id]):
            summaries_text += f"{i + 1}. {summary['content']} (æ—¶é—´:{summary['timestamp']})\n"
        return event.plain_result(summaries_text)

    @memory.command("summary")
    async def create_summary(self, event: AstrMessageEvent):
        """æ€»ç»“å¹¶ä¿å­˜è‡ªä¸Šæ¬¡æ€»ç»“ä»¥æ¥çš„æ–°å¯¹è¯"""
        session_id = self._get_unified_session_id(event)
        await self._create_summary_internal(session_id, event)

    @memory.command("clear")
    async def clear_summaries(self, event: AstrMessageEvent):
        """æ¸…ç©ºå½“å‰ä¼šè¯çš„æ‰€æœ‰æ‘˜è¦"""
        session_id = self._get_unified_session_id(event)
        if session_id in self.summaries:
            del self.summaries[session_id]
            await self._save_summaries()
            return event.plain_result("å·²æ¸…ç©ºæ‰€æœ‰æ‘˜è¦ã€‚")
        return event.plain_result("å½“å‰ä¼šè¯æ²¡æœ‰æ‘˜è¦ã€‚")

    @memory.command("remove")
    async def remove_summary(self, event: AstrMessageEvent, index: int):
        """åˆ é™¤æŒ‡å®šåºå·çš„æ‘˜è¦"""
        session_id = self._get_unified_session_id(event)
        if session_id not in self.summaries:
            return event.plain_result("å½“å‰ä¼šè¯æ²¡æœ‰æ‘˜è¦ã€‚")

        summaries = self.summaries[session_id]
        index = index - 1
        if index < 0 or index >= len(summaries):
            return event.plain_result("æ— æ•ˆçš„æ‘˜è¦åºå·ã€‚")

        removed = summaries.pop(index)
        await self._save_summaries()
        return event.plain_result(f"å·²åˆ é™¤æ‘˜è¦: {removed['content']}")

    @command("mem_help")
    async def memory_help(self, event: AstrMessageEvent):
        """æ˜¾ç¤ºè®°å¿†æ’ä»¶å¸®åŠ©ä¿¡æ¯"""
        help_text = f"""è®°å¿†æ’ä»¶ä½¿ç”¨å¸®åŠ©ï¼š

1. è®°å¿†ç®¡ç†æŒ‡ä»¤ï¼š
    /memory list - åˆ—å‡ºæ‰€æœ‰æ‘˜è¦
    /memory summary - æ€»ç»“å¹¶ä¿å­˜ä¹‹å‰çš„å¯¹è¯
    /memory clear - æ¸…ç©ºå½“å‰ä¼šè¯çš„æ‰€æœ‰æ‘˜è¦
    /memory remove <åºå·> - åˆ é™¤æŒ‡å®šåºå·çš„æ‘˜è¦
    /mem_help - æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯

2. è®°å¿†ç‰¹æ€§ï¼š
    - æ¯ä¸ªä¼šè¯æœ€å¤šä¿å­˜{self.max_summaries}æ¡æ‘˜è¦
    - AI åœ¨å¯¹è¯æ—¶ä¼šå‚è€ƒå†å²æ‘˜è¦, å®ç°é•¿ä¹…è®°å¿†
    - æ¯{self.auto_summary_interval}è½®å¯¹è¯è‡ªåŠ¨è¿›è¡Œä¸€æ¬¡æ€»ç»“
        """

        return event.plain_result(help_text)

    async def _get_lock(self, session_id: str) -> asyncio.Lock:
        """è·å–æˆ–åˆ›å»ºä¼šè¯é”"""
        if session_id not in self.locks:
            self.locks[session_id] = asyncio.Lock()
        return self.locks[session_id]

    async def _append_to_memory_data(self, session_id: str, role: str, content: str, event: AstrMessageEvent):
        """å°†æ¶ˆæ¯è¿½åŠ åˆ° memory_data.jsonï¼Œå¹¶æ›´æ–°è®¡æ•°å™¨"""
        if session_id not in self.memory_data:
            self.memory_data[session_id] = {"messages": [], "count": 0, "last_summary_index": -1}

        message = {
            "role": role,
            "content": content,
            "timestamp": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        self.memory_data[session_id]["messages"].append(message)
        self.memory_data[session_id]["count"] += 1

        await self._save_memory_data()

        # æ£€æŸ¥æ˜¯å¦éœ€è¦è‡ªåŠ¨æ€»ç»“
        if self.memory_data[session_id]["count"] % self.auto_summary_interval == 0:
            await self._create_summary_internal(session_id, None)  # è‡ªåŠ¨æ€»ç»“ï¼Œä¼ å…¥ None


    async def _save_memory_data(self):
        """ä¿å­˜ memory_data.json"""
        with open(self.memory_file, "w", encoding='utf-8') as f:
            json.dump(self.memory_data, f, ensure_ascii=False, indent=4)

    async def _save_summaries(self):
        """ä¿å­˜æ‘˜è¦åˆ°æ–‡ä»¶"""
        with open(self.summary_file, "w", encoding='utf-8') as f:
            json.dump(self.summaries, f, ensure_ascii=False, indent=4)

    def _get_unified_session_id(self, event: AstrMessageEvent) -> str:
        return event.unified_msg_origin

    async def _create_summary_internal(self, session_id: str, event: AstrMessageEvent):
        """å†…éƒ¨æ–¹æ³•ï¼šæ€»ç»“å¹¶ä¿å­˜è‡ªä¸Šæ¬¡æ€»ç»“ä»¥æ¥çš„æ–°å¯¹è¯, ä¾›æ‰‹åŠ¨å’Œè‡ªåŠ¨è°ƒç”¨"""

        if session_id not in self.memory_data:
            self.memory_data[session_id] = {"messages": [], "count": 0, "last_summary_index": -1}

        last_summary_index = self.memory_data[session_id].get("last_summary_index", -1)
        new_messages = self.memory_data[session_id]["messages"][last_summary_index + 1:]

        if not new_messages:
            if event: # æ‰‹åŠ¨è°ƒç”¨æ—¶å‘é€
                await event.send("æ²¡æœ‰æ–°çš„å¯¹è¯éœ€è¦æ€»ç»“ã€‚")
            return

        conversation_history = ""
        for entry in new_messages:
            conversation_history += f"{entry['role']}: {entry['content']}\n"

        summary_text = await self._summarize_text_with_siliconflow(conversation_history)

        if not summary_text:
            if event:  # åªæœ‰æ‰‹åŠ¨è°ƒç”¨æ—¶æ‰å‘é€
                await event.send("æ€»ç»“å¤±è´¥ï¼šæ²¡æœ‰ç”Ÿæˆæ‘˜è¦ã€‚")
            return

        await self._save_summary(session_id, summary_text)
        self.memory_data[session_id]["last_summary_index"] = len(self.memory_data[session_id]["messages"]) - 1
        await self._save_memory_data()
        if event: # æ‰‹åŠ¨è°ƒç”¨æ—¶å‘é€
            await event.send(f"å·²ç”Ÿæˆå¹¶ä¿å­˜å¯¹è¯æ‘˜è¦ï¼š\n{summary_text}")
        logger.info(f"ä¼šè¯ {session_id} å·²æ€»ç»“ï¼š\n{summary_text}")

    async def _summarize_text_with_siliconflow(self, text: str) -> str:
        """ä½¿ç”¨ç¡…åŸºæµåŠ¨ API æ€»ç»“æ–‡æœ¬"""

        if not text:
            return ""

        url = "https://api.siliconflow.cn/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {self.siliconflow_api_key}",
            "Content-Type": "application/json"
        }
        data = {
            "model": self.siliconflow_model,
            "messages": [
                {
                    "role": "user",
                    "content": f"è¯·å¯¹ä»¥ä¸‹å¯¹è¯è¿›è¡Œæ€»ç»“æ‘˜è¦ï¼š\n{text}\næ‘˜è¦åº”ç®€æ´ã€æ¸…æ™°ï¼Œå¹¶åŒ…å«å…³é”®ä¿¡æ¯ã€‚"
                }
            ],
            "stream": False,
            "max_tokens": 512,
            "stop": ["null"],
            "temperature": 0.7,
            "top_p": 0.7,
            "top_k": 50,
            "frequency_penalty": 0.5,
            "n": 1,
            "response_format": {"type": "text"},
            "tools": []
        }
        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(url, headers=headers, json=data, timeout=60)
                response.raise_for_status()
                result = response.json()
                logger.debug(f"ç¡…åŸºæµåŠ¨ API å“åº”: {result}")

                if "choices" in result and result["choices"] and result["choices"][0].get("message", {}).get(
                        "content"):
                    summary = result["choices"][0]["message"]["content"]
                    return summary
                else:
                    error_message = result.get("message", "æœªçŸ¥é”™è¯¯")
                    logger.error(f"ç¡…åŸºæµåŠ¨ API é”™è¯¯: {error_message} æˆ– è¿”å›ç»“æœæ ¼å¼é”™è¯¯:{result}")
                    return f"æ€»ç»“å¤±è´¥: {error_message}"

        except httpx.HTTPStatusError as e:
            logger.error(f"HTTP çŠ¶æ€ç é”™è¯¯: {e.response.status_code} - {e}")
            return f"æ€»ç»“å¤±è´¥ï¼šHTTP çŠ¶æ€ç é”™è¯¯ - {e.response.status_code}"
        except httpx.RequestError as e:
            logger.error(f"HTTP è¯·æ±‚é”™è¯¯: {e}")
            return f"æ€»ç»“å¤±è´¥ï¼šHTTP è¯·æ±‚é”™è¯¯ - {e}"
        except Exception as e:
            logger.exception(f"æ€»ç»“æ—¶å‘ç”Ÿå…¶ä»–é”™è¯¯: {e}")
            return f"æ€»ç»“å¤±è´¥ï¼š{e}"


    async def _save_summary(self, session_id: str, summary_text: str):
        """ä¿å­˜æ‘˜è¦"""
        if session_id not in self.summaries:
            self.summaries[session_id] = []
        try:
            if len(self.summaries[session_id]) >= self.max_summaries:
                self.summaries[session_id].pop(0)
        except Exception as e:
            logger.exception(f"åˆ é™¤æ—§æ‘˜è¦æ—¶å‡ºé”™: {e}")

        summary = {
            "content": summary_text,
            "timestamp": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        self.summaries[session_id].append(summary)
        await self._save_summaries()

    async def _get_relevant_summaries(self, session_id: str, query: str) -> List[str]:
        """æ ¹æ®ç›¸ä¼¼åº¦è·å–ç›¸å…³çš„æ‘˜è¦"""
        if session_id not in self.summaries or not self.summaries[session_id]:
            return []

        query_embedding = self.embedding_model.encode(query, convert_to_tensor=True)
        relevant_summaries = []

        for summary in self.summaries[session_id]:
            summary_embedding = self.embedding_model.encode(summary['content'], convert_to_tensor=True)
            similarity = util.pytorch_cos_sim(query_embedding, summary_embedding)[0][0]

            if similarity >= self.similarity_threshold:
                relevant_summaries.append((summary['content'], similarity))

        relevant_summaries.sort(key=lambda x: x[1], reverse=True)
        return [summary for summary, _ in relevant_summaries[:3]]

    @llm_tool(name="get_memories")
    async def get_memories(self, event: AstrMessageEvent, current_input: str = "") -> str:
        """LLMå·¥å…·ï¼šè·å–ç›¸å…³è®°å¿†"""
        session_id = self._get_unified_session_id(event)
        relevant_summaries = await self._get_relevant_summaries(session_id, current_input)
        if relevant_summaries:
            return "ğŸ’­ ç›¸å…³æ‘˜è¦ï¼š\n" + "\n".join([f"- {s}" for s in relevant_summaries])

        return "æˆ‘æ²¡æœ‰ä»»ä½•ç›¸å…³è®°å¿†ã€‚"

    @on_decorating_result()
    async def _record_all_messages(self, event: AstrMessageEvent):
        session_id = self._get_unified_session_id(event)
        curr_cid = await self.context.conversation_manager.get_curr_conversation_id(event.unified_msg_origin)
        if not curr_cid:
            return
        conversation = await self.context.conversation_manager.get_conversation(event.unified_msg_origin, curr_cid)
        if not conversation:
            return

        history = json.loads(conversation.history)
        if len(history) >= 2:
            last_user_message = history[-2]
            last_ai_message = history[-1]

            if last_user_message:
                await self._append_to_memory_data(session_id, last_user_message['role'], last_user_message['content'], event)
            if last_ai_message:
                await self._append_to_memory_data(session_id, last_ai_message['role'], last_ai_message['content'], event)